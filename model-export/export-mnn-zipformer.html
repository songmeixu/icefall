<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Export streaming Zipformer transducer models to MNN &mdash; icefall 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=e031e9a9"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Recipes" href="../recipes/index.html" />
    <link rel="prev" title="Export to mnn" href="export-mnn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            icefall
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../for-dummies/index.html">Icefall for dummies tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker/index.html">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faqs.html">Frequently Asked Questions (FAQs)</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Model export</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="export-model-state-dict.html">Export model.state_dict()</a></li>
<li class="toctree-l2"><a class="reference internal" href="export-with-torch-jit-trace.html">Export model with torch.jit.trace()</a></li>
<li class="toctree-l2"><a class="reference internal" href="export-with-torch-jit-script.html">Export model with torch.jit.script()</a></li>
<li class="toctree-l2"><a class="reference internal" href="export-onnx.html">Export to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="export-ncnn.html">Export to ncnn</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="export-mnn.html">Export to mnn</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Export streaming Zipformer transducer models to MNN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#download-the-pre-trained-model">1. Download the pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-mnn">1. Install MNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#export-the-model-to-onnx">2. Export the model to ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="#convert-model-from-onnx-to-mnn">3. Convert model from onnx to MNN</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/index.html">Recipes</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../huggingface/index.html">Huggingface</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../decoding-with-langugage-models/index.html">Decoding with language models</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">icefall</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Model export</a></li>
          <li class="breadcrumb-item"><a href="export-mnn.html">Export to mnn</a></li>
      <li class="breadcrumb-item active">Export streaming Zipformer transducer models to MNN</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/icefall/blob/master/docs/source/model-export/export-mnn-zipformer.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="export-streaming-zipformer-transducer-models-to-mnn">
<span id="id1"></span><h1>Export streaming Zipformer transducer models to MNN<a class="headerlink" href="#export-streaming-zipformer-transducer-models-to-mnn" title="Permalink to this heading"></a></h1>
<p>We use the pre-trained model from the following repository as an example:</p>
<p><a class="reference external" href="https://huggingface.co/pfluo/k2fsa-zipformer-bilingual-zh-en-t">https://huggingface.co/pfluo/k2fsa-zipformer-bilingual-zh-en-t</a></p>
<p>We will show you step by step how to export it to <a href="#id2"><span class="problematic" id="id3">`MNN`_</span></a> and run it with <a href="#id4"><span class="problematic" id="id5">`sherpa-MNN`_</span></a>.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">Ubuntu</span> <span class="pre">20.04</span></code>, <code class="docutils literal notranslate"><span class="pre">torch</span> <span class="pre">2.0.0</span></code>, and <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">3.8</span></code> for testing.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Please use a more recent version of PyTorch. For instance, <code class="docutils literal notranslate"><span class="pre">torch</span> <span class="pre">1.8</span></code>
may <code class="docutils literal notranslate"><span class="pre">not</span></code> work.</p>
</div>
<section id="download-the-pre-trained-model">
<h2>1. Download the pre-trained model<a class="headerlink" href="#download-the-pre-trained-model" title="Permalink to this heading"></a></h2>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You have to install <a class="reference external" href="https://git-lfs.com/">git-lfs</a> before you continue.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>egs/librispeech/ASR
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/pfluo/k2fsa-zipformer-bilingual-zh-en-t

<span class="nb">cd</span><span class="w"> </span>..
</pre></div>
</div>
<p>In the above code, we downloaded the pre-trained model into the directory
<code class="docutils literal notranslate"><span class="pre">egs/librispeech/ASR/k2fsa-zipformer-bilingual-zh-en-t</span></code>.</p>
</section>
<section id="install-mnn">
<span id="export-for-mnn-install-mnn"></span><h2>1. Install MNN<a class="headerlink" href="#install-mnn" title="Permalink to this heading"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># We put MNN into $HOME/open-source/MNN</span>
<span class="c1"># You can change it to anywhere you like</span>

<span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>open-source
<span class="nb">cd</span><span class="w"> </span>open-source

git<span class="w"> </span>clone<span class="w"> </span>https://github.com/alibaba/MNN
<span class="nb">cd</span><span class="w"> </span>MNN
mkdir<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build

cmake<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_CONVERTER<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_TORCH<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_TOOLS<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_BENCHMARK<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_EVALUATION<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_DEMO<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_TEST<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-DMNN_BUILD_QUANTOOLS<span class="o">=</span>ON
..

make<span class="w"> </span>-j4

<span class="nb">cd</span><span class="w"> </span>..

<span class="c1"># Note: $PWD here is $HOME/open-source/MNN</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PWD</span>/build:<span class="nv">$PATH</span>
</pre></div>
</div>
<p>Congratulations! You have successfully installed the following components:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MNNConvert</span></code>, which is an executable located in
<code class="docutils literal notranslate"><span class="pre">$HOME/open-source/MNN/build</span></code>. We will use
it to convert models from <code class="docutils literal notranslate"><span class="pre">ONNX</span></code>.</p></li>
</ul>
</div></blockquote>
</section>
<section id="export-the-model-to-onnx">
<h2>2. Export the model to ONNX<a class="headerlink" href="#export-the-model-to-onnx" title="Permalink to this heading"></a></h2>
<p>First, let us rename our pre-trained model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">egs</span><span class="o">/</span><span class="n">librispeech</span><span class="o">/</span><span class="n">ASR</span>

<span class="n">cd</span> <span class="n">k2fsa</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">bilingual</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">t</span><span class="o">/</span><span class="n">exp</span>

<span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="n">pretrained</span><span class="o">.</span><span class="n">pt</span> <span class="n">epoch</span><span class="o">-</span><span class="mf">99.</span><span class="n">pt</span>

<span class="n">cd</span> <span class="o">../..</span>
</pre></div>
</div>
<p>Next, we use the following code to export our model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">dir</span><span class="o">=</span>./k2fsa-zipformer-bilingual-zh-en-t

./pruned_transducer_stateless7_streaming/export-onnx-zh.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span><span class="nv">$dir</span>/data/lang_char_bpe/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--exp-dir<span class="w"> </span><span class="nv">$dir</span>/exp<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--use-averaged-model<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--epoch<span class="w"> </span><span class="m">99</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--avg<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decode-chunk-len<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-encoder-layers<span class="w"> </span><span class="s2">&quot;2,2,2,2,2&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--feedforward-dims<span class="w"> </span><span class="s2">&quot;768,768,768,768,768&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--nhead<span class="w"> </span><span class="s2">&quot;4,4,4,4,4&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder-dims<span class="w"> </span><span class="s2">&quot;256,256,256,256,256&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--attention-dims<span class="w"> </span><span class="s2">&quot;192,192,192,192,192&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder-unmasked-dims<span class="w"> </span><span class="s2">&quot;192,192,192,192,192&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--zipformer-downsampling-factors<span class="w"> </span><span class="s2">&quot;1,2,4,8,2&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--cnn-module-kernels<span class="w"> </span><span class="s2">&quot;31,31,31,31,31&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder-dim<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner-dim<span class="w"> </span><span class="m">512</span>
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If your model has different configuration parameters, please change them accordingly.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>We have renamed our model to <code class="docutils literal notranslate"><span class="pre">epoch-99.pt</span></code> so that we can use <code class="docutils literal notranslate"><span class="pre">--epoch</span> <span class="pre">99</span></code>.
There is only one pre-trained model, so we use <code class="docutils literal notranslate"><span class="pre">--avg</span> <span class="pre">1</span> <span class="pre">--use-averaged-model</span> <span class="pre">0</span></code>.</p>
<p>If you have trained a model by yourself and if you have all checkpoints
available, please first use <code class="docutils literal notranslate"><span class="pre">decode.py</span></code> to tune <code class="docutils literal notranslate"><span class="pre">--epoch</span> <span class="pre">--avg</span></code>
and select the best combination with with <code class="docutils literal notranslate"><span class="pre">--use-averaged-model</span> <span class="pre">1</span></code>.</p>
</div>
<p>After the above step, we will get the following files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls<span class="w"> </span>-lh<span class="w"> </span>k2fsa-zipformer-bilingual-zh-en-t/exp/*.onnx

.rw-rw-r--<span class="w">  </span><span class="m">88</span>,435,414<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-12<span class="w"> </span><span class="m">10</span>:05<span class="w"> </span>encoder-epoch-99-avg-1.onnx
.rw-rw-r--<span class="w">  </span><span class="m">13</span>,876,389<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-12<span class="w"> </span><span class="m">10</span>:05<span class="w"> </span>decoder-epoch-99-avg-1.onnx
.rw-rw-r--<span class="w">  </span><span class="m">12</span>,833,674<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-12<span class="w"> </span><span class="m">10</span>:05<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="convert-model-from-onnx-to-mnn">
<span id="zipformer-transducer-step-4-export-torchscript-model-via-pnnx"></span><h2>3. Convert model from onnx to MNN<a class="headerlink" href="#convert-model-from-onnx-to-mnn" title="Permalink to this heading"></a></h2>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Make sure you have set up the <code class="docutils literal notranslate"><span class="pre">PATH</span></code> environment variable
in <span class="xref std std-ref">_export_for_mnn_install_mnn</span>. Otherwise,
it will throw an error saying that <code class="docutils literal notranslate"><span class="pre">MNNConvert</span></code> could not be found.</p>
</div>
<p>Now, it’s time to export our models to <a href="#id6"><span class="problematic" id="id7">`MNN`_</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">k2fsa</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">bilingual</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">t</span><span class="o">/</span><span class="n">exp</span><span class="o">/</span>

<span class="n">MNNConvert</span> <span class="o">-</span><span class="n">f</span> <span class="n">ONNX</span> <span class="o">--</span><span class="n">modelFile</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">onnx</span> <span class="o">--</span><span class="n">MNNModel</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">mnn</span> <span class="o">--</span><span class="n">bizCode</span> <span class="n">MNN</span>
<span class="n">MNNConvert</span> <span class="o">-</span><span class="n">f</span> <span class="n">ONNX</span> <span class="o">--</span><span class="n">modelFile</span> <span class="n">decoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">onnx</span> <span class="o">--</span><span class="n">MNNModel</span> <span class="n">decoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">mnn</span> <span class="o">--</span><span class="n">bizCode</span> <span class="n">MNN</span>
<span class="n">MNNConvert</span> <span class="o">-</span><span class="n">f</span> <span class="n">ONNX</span> <span class="o">--</span><span class="n">modelFile</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">onnx</span> <span class="o">--</span><span class="n">MNNModel</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">99</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">1.</span><span class="n">mnn</span> <span class="o">--</span><span class="n">bizCode</span> <span class="n">MNN</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will see the following log output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># encoder
/audio/code/MNN/build/MNNConvert -f ONNX --modelFile encoder-epoch-99-avg-1.onnx --MNNModel encoder-epoch-99-avg-1.mnn --bizCode MNN
The device support i8sdot:0, support fp16:0, support i8mm: 0
Start to Convert Other Model Format To MNN Model...
[16:52:23] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:98: ONNX Model ir version: 7
[16:52:23] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:99: ONNX Model opset version: 13
Start to Optimize the MNN Net...
88 op name is empty or dup, set to Unsqueeze88
188 op name is empty or dup, set to Unsqueeze188
215 op name is empty or dup, set to Shape215
...
inputTensors : [ x, cached_avg_0, cached_len_0, cached_key_0, cached_val_0, cached_conv1_0, cached_val2_0, cached_conv2_0, cached_avg_1, cached_len_1, cached_key_1, cached_val_1, cached_conv1_1, cached_val2_1, cached_conv2_1, cached_avg_2, cached_len_2, cached_key_2, cached_val_2, cached_conv1_2, cached_val2_2, cached_conv2_2, cached_avg_3, cached_len_3, cached_key_3, cached_val_3, cached_conv1_3, cached_val2_3, cached_conv2_3, cached_avg_4, cached_len_4, cached_key_4, cached_val_4, cached_conv1_4, cached_val2_4, cached_conv2_4, ]
outputTensors: [ encoder_out, new_cached_avg_0, new_cached_avg_1, new_cached_avg_2, new_cached_avg_3, new_cached_avg_4, new_cached_conv1_0, new_cached_conv1_1, new_cached_conv1_2, new_cached_conv1_3, new_cached_conv1_4, new_cached_conv2_0, new_cached_conv2_1, new_cached_conv2_2, new_cached_conv2_3, new_cached_conv2_4, new_cached_key_0, new_cached_key_1, new_cached_key_2, new_cached_key_3, new_cached_key_4, new_cached_len_0, new_cached_len_1, new_cached_len_2, new_cached_len_3, new_cached_len_4, new_cached_val2_0, new_cached_val2_1, new_cached_val2_2, new_cached_val2_3, new_cached_val2_4, new_cached_val_0, new_cached_val_1, new_cached_val_2, new_cached_val_3, new_cached_val_4, ]
Converted Success!

# decoder
/audio/code/MNN/build/MNNConvert -f ONNX --modelFile decoder-epoch-99-avg-1.onnx --MNNModel decoder-epoch-99-avg-1.mnn --bizCode MNN
The device support i8sdot:0, support fp16:0, support i8mm: 0
Start to Convert Other Model Format To MNN Model...
[16:51:58] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:98: ONNX Model ir version: 7
[16:51:58] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:99: ONNX Model opset version: 13
Start to Optimize the MNN Net...
167 op name is empty or dup, set to Unsqueeze167
inputTensors : [ y, ]
outputTensors: [ decoder_out, ]
The model has subgraphs, please use MNN::Module to run it
Converted Success!

# joiner
/audio/code/MNN/build/MNNConvert -f ONNX --modelFile joiner-epoch-99-avg-1.onnx --MNNModel joiner-epoch-99-avg-1.mnn --bizCode MNN
The device support i8sdot:0, support fp16:0, support i8mm: 0
Start to Convert Other Model Format To MNN Model...
[16:51:01] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:98: ONNX Model ir version: 7
[16:51:01] /audio/code/MNN/tools/converter/source/onnx/onnxConverter.cpp:99: ONNX Model opset version: 13
Start to Optimize the MNN Net...
inputTensors : [ encoder_out, decoder_out, ]
outputTensors: [ logit, ]
Converted Success!
</pre></div>
</div>
</div>
<p>It will generate the following files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls<span class="w"> </span>-lh<span class="w"> </span>k2fsa-zipformer-bilingual-zh-en-t/exp/*.mnn

.rw-rw-r--<span class="w">  </span><span class="m">12</span>,836,004<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-09<span class="w"> </span><span class="m">15</span>:12<span class="w"> </span>joiner-epoch-99-avg-1.mnn
.rw-rw-r--<span class="w">  </span><span class="m">13</span>,917,864<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-09<span class="w"> </span><span class="m">15</span>:12<span class="w"> </span>decoder-epoch-99-avg-1.mnn
.rw-rw-r--<span class="w">  </span><span class="m">89</span>,065,932<span class="w"> </span>meixu<span class="w"> </span><span class="m">2023</span>-05-09<span class="w"> </span><span class="m">15</span>:13<span class="w"> </span>encoder-epoch-99-avg-1.mnn
</pre></div>
</div>
<p>Congratulations! You have successfully exported a model from PyTorch to <a href="#id8"><span class="problematic" id="id9">`MNN`_</span></a>!</p>
<p>Now you can use this model in <a href="#id10"><span class="problematic" id="id11">`sherpa-mnn`_</span></a>.
Please refer to the following documentation:</p>
<blockquote>
<div><ul class="simple">
<li><p>Linux/aarch64: <a class="reference external" href="https://k2-fsa.github.io/sherpa/mnn/install/index.html">https://k2-fsa.github.io/sherpa/mnn/install/index.html</a></p></li>
</ul>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="export-mnn.html" class="btn btn-neutral float-left" title="Export to mnn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../recipes/index.html" class="btn btn-neutral float-right" title="Recipes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, icefall development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>